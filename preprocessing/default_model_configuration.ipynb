{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# for data analytics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# for visualizations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for data preparation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "\n",
    "# imblean provides tools for us to deal with imbalanced class sizes\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "# example of random oversampling to balance the class distribution\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# machine learning models\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# for evaluation of machine learning models\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../datasets/glove/train_data_imputed_FINAL.csv')\n",
    "X_test = pd.read_csv('../datasets/glove/test_data_imputed_FINAL.csv')\n",
    "y_train = pd.read_csv('../datasets/glove/y_train_FINAL.csv')\n",
    "y_test = pd.read_csv('../datasets/glove/y_test_FINAL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wordvec = pd.read_csv('../datasets/word2vec/train_data_imputed_FINAL.csv')\n",
    "X_test_wordvec = pd.read_csv('../datasets/word2vec/test_data_imputed_FINAL.csv')\n",
    "y_train_wordvec = pd.read_csv('../datasets/word2vec/y_train_FINAL.csv')['fraudulent']\n",
    "y_test_wordvec = pd.read_csv('../datasets/word2vec/y_test_FINAL.csv')['fraudulent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_train, y_test, y_train_pred, y_test_pred):\n",
    "    train_results = {}\n",
    "    train_results['Accuracy'] = metrics.accuracy_score(y_train, y_train_pred)\n",
    "    train_results['Precision'] = metrics.precision_score(y_train, y_train_pred)\n",
    "    train_results['Recall'] = metrics.recall_score(y_train, y_train_pred)\n",
    "    train_results['F1'] = metrics.f1_score(y_train, y_train_pred)\n",
    "\n",
    "    test_results = {}\n",
    "    test_results['Accuracy'] = metrics.accuracy_score(y_test, y_test_pred)\n",
    "    test_results['Precision'] = metrics.precision_score(y_test, y_test_pred)\n",
    "    test_results['Recall'] = metrics.recall_score(y_test, y_test_pred)\n",
    "    test_results['F1'] = metrics.f1_score(y_test, y_test_pred)\n",
    "\n",
    "    # print('-----  TRAIN METRICS -----')\n",
    "    # print(f'Accuracy: {metrics.accuracy_score(y_train, y_train_pred)}')\n",
    "    # print(f'Precision: {metrics.precision_score(y_train, y_train_pred)}')\n",
    "    # print(f'Recall: {metrics.recall_score(y_train, y_train_pred)}')\n",
    "    # print(f'F1: {metrics.f1_score(y_train, y_train_pred)}')\n",
    "    # print(f'Confusion Matrix:\\n {metrics.confusion_matrix(y_train, y_train_pred)}')\n",
    "    \n",
    "    # print('-----  TEST METRICS -----')\n",
    "    # print(f'Accuracy: {metrics.accuracy_score(y_test, y_test_pred)}')\n",
    "    # print(f'Precision: {metrics.precision_score(y_test, y_test_pred)}')\n",
    "    # print(f'Recall: {metrics.recall_score(y_test, y_test_pred)}')\n",
    "    # print(f'F1: {metrics.f1_score(y_test, y_test_pred)}')\n",
    "    # print(f'Confusion Matrix:\\n {metrics.confusion_matrix(y_test, y_test_pred)}')\n",
    "\n",
    "    return train_results, test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n",
      "11293\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train[y_train['fraudulent'] == 1]))\n",
    "print(len(y_train[y_train['fraudulent'] == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMOTE_ENN(X_train, y_train, n_neighbours, k_neighbours, sampling_strategy):\n",
    "    # SMOTE ENN oversampling\n",
    "    smote_only = SMOTE(random_state=42, sampling_strategy=sampling_strategy, k_neighbors = k_neighbours)\n",
    "    ennObj = EditedNearestNeighbours(n_neighbors=n_neighbours)\n",
    "    smote_enn = SMOTEENN(random_state=42, smote=smote_only , enn= ennObj)\n",
    "    X_res_smoteENN, y_res_smoteENN = smote_enn.fit_resample(X_train, y_train)\n",
    "    return X_res_smoteENN, y_res_smoteENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_oversampler(X_train, y_train):\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "    X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "    return X_over, y_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adasyn(X_train, y_train, n_neighbors):\n",
    "    ada = ADASYN(sampling_strategy = 'minority', n_neighbors = n_neighbors)\n",
    "    X_resampled, y_resampled = ADASYN().fit_sample(X_train, y_train)\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg(X_train,y_train, X_test, y_test):\n",
    "    lr = LogisticRegression()\n",
    "    lr_model = lr.fit(X_train, y_train)\n",
    "    y_train_pred = lr_model.predict(X_train)\n",
    "    y_test_pred = lr_model.predict(X_test)\n",
    "    train_results, test_results = evaluate(y_train,y_test,y_train_pred,y_test_pred)\n",
    "    return train_results, test_results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune SMOTE ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = (1,10)\n",
    "k_neighbors = [1,10]\n",
    "sampling_strategy = [0.2,0.8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "nneighbors = []\n",
    "kneighbors = []\n",
    "samplingstrat = []\n",
    "train_accuracy = []\n",
    "train_precision = []\n",
    "train_recall = []\n",
    "train_f1 = []\n",
    "\n",
    "test_accuracy = []\n",
    "test_precision = []\n",
    "test_recall = []\n",
    "test_f1 = []\n",
    "\n",
    "for i in list(range(n_neighbors[0], n_neighbors[1])):\n",
    "    print(i)\n",
    "    for k in list(range(k_neighbors[0], k_neighbors[1])):\n",
    "        for j in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "            X_train_SMOTE, y_train_SMOTE = SMOTE_ENN(X_train, y_train, n_neighbours = i, k_neighbours = k, sampling_strategy = j)\n",
    "            train_results, test_results = log_reg(X_train_SMOTE,y_train_SMOTE,X_test,y_test)\n",
    "            nneighbors.append(i)\n",
    "            kneighbors.append(k)\n",
    "            samplingstrat.append(j)\n",
    "            train_accuracy.append(train_results['Accuracy'])\n",
    "            train_precision.append(train_results['Precision'])\n",
    "            train_recall.append(train_results['Recall'])\n",
    "            train_f1.append(train_results['F1'])\n",
    "\n",
    "            test_accuracy.append(test_results['Accuracy'])\n",
    "            test_precision.append(test_results['Precision'])\n",
    "            test_recall.append(test_results['Recall'])\n",
    "            test_f1.append(test_results['F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_results = pd.DataFrame()\n",
    "smote_results['nneighbors'] = nneighbors\n",
    "smote_results['kneighbors'] = kneighbors\n",
    "smote_results['samplingstrat'] = samplingstrat\n",
    "smote_results['train_accuracy'] = train_accuracy\n",
    "smote_results['train_precision'] = train_precision\n",
    "smote_results['train_recall'] = train_recall\n",
    "smote_results['train_f1'] = train_f1\n",
    "smote_results['test_accuracy'] = test_accuracy\n",
    "smote_results['test_precision'] = test_precision\n",
    "smote_results['test_recall'] = test_recall\n",
    "smote_results['test_f1'] = test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nneighbors</th>\n",
       "      <th>kneighbors</th>\n",
       "      <th>samplingstrat</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.938055</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.488928</td>\n",
       "      <td>0.592275</td>\n",
       "      <td>0.972917</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.938506</td>\n",
       "      <td>0.757453</td>\n",
       "      <td>0.495128</td>\n",
       "      <td>0.598822</td>\n",
       "      <td>0.972917</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     nneighbors  kneighbors  samplingstrat  train_accuracy  train_precision  \\\n",
       "162           3           1            0.1        0.938055         0.751020   \n",
       "180           3           3            0.1        0.938506         0.757453   \n",
       "\n",
       "     train_recall  train_f1  test_accuracy  test_precision  test_recall  \\\n",
       "162      0.488928  0.592275       0.972917        0.328125        0.375   \n",
       "180      0.495128  0.598822       0.972917        0.328125        0.375   \n",
       "\n",
       "     test_f1  \n",
       "162     0.35  \n",
       "180     0.35  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_results[smote_results['test_f1'] == smote_results['test_f1'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "nneighbors = []\n",
    "kneighbors = []\n",
    "samplingstrat = []\n",
    "train_accuracy = []\n",
    "train_precision = []\n",
    "train_recall = []\n",
    "train_f1 = []\n",
    "\n",
    "test_accuracy = []\n",
    "test_precision = []\n",
    "test_recall = []\n",
    "test_f1 = []\n",
    "\n",
    "for i in list(range(n_neighbors[0], n_neighbors[1])):\n",
    "    print(i)\n",
    "    for k in list(range(k_neighbors[0], k_neighbors[1])):\n",
    "        for j in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "            X_train_SMOTE, y_train_SMOTE = SMOTE_ENN(X_train_wordvec, y_train_wordvec, n_neighbours = i, k_neighbours = k, sampling_strategy = j)\n",
    "            train_results, test_results = log_reg(X_train_SMOTE,y_train_SMOTE,X_test_wordvec,y_test_wordvec)\n",
    "            nneighbors.append(i)\n",
    "            kneighbors.append(k)\n",
    "            samplingstrat.append(j)\n",
    "            train_accuracy.append(train_results['Accuracy'])\n",
    "            train_precision.append(train_results['Precision'])\n",
    "            train_recall.append(train_results['Recall'])\n",
    "            train_f1.append(train_results['F1'])\n",
    "\n",
    "            test_accuracy.append(test_results['Accuracy'])\n",
    "            test_precision.append(test_results['Precision'])\n",
    "            test_recall.append(test_results['Recall'])\n",
    "            test_f1.append(test_results['F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_results_wordvec = pd.DataFrame()\n",
    "smote_results_wordvec['nneighbors'] = nneighbors\n",
    "smote_results_wordvec['kneighbors'] = kneighbors\n",
    "smote_results_wordvec['samplingstrat'] = samplingstrat\n",
    "smote_results_wordvec['train_accuracy'] = train_accuracy\n",
    "smote_results_wordvec['train_precision'] = train_precision\n",
    "smote_results_wordvec['train_recall'] = train_recall\n",
    "smote_results_wordvec['train_f1'] = train_f1\n",
    "smote_results_wordvec['test_accuracy'] = test_accuracy\n",
    "smote_results_wordvec['test_precision'] = test_precision\n",
    "smote_results_wordvec['test_recall'] = test_recall\n",
    "smote_results_wordvec['test_f1'] = test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nneighbors</th>\n",
       "      <th>kneighbors</th>\n",
       "      <th>samplingstrat</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.96123</td>\n",
       "      <td>0.819149</td>\n",
       "      <td>0.750221</td>\n",
       "      <td>0.783172</td>\n",
       "      <td>0.976042</td>\n",
       "      <td>0.430108</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.536913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     nneighbors  kneighbors  samplingstrat  train_accuracy  train_precision  \\\n",
       "288           4           6            0.1         0.96123         0.819149   \n",
       "\n",
       "     train_recall  train_f1  test_accuracy  test_precision  test_recall  \\\n",
       "288      0.750221  0.783172       0.976042        0.430108     0.714286   \n",
       "\n",
       "      test_f1  \n",
       "288  0.536913  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_results_wordvec[smote_results_wordvec['test_f1'] == smote_results_wordvec['test_f1'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random oversampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.8747011423005402, 'Precision': 0.8689510855349202, 'Recall': 0.8824935800938635, 'F1': 0.8756699762762499}\n",
      "{'Accuracy': 0.8517361111111111, 'Precision': 0.08685968819599109, 'Recall': 0.6964285714285714, 'F1': 0.15445544554455445}\n"
     ]
    }
   ],
   "source": [
    "X_train_oversampler, y_train_oversampler = random_oversampler(X_train, y_train)\n",
    "train_results, test_results = log_reg(X_train_oversampler,y_train_oversampler,X_test,y_test)\n",
    "print(train_results)\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.936730718143983, 'Precision': 0.9178952719877986, 'Recall': 0.9592668024439919, 'F1': 0.9381251353106733}\n",
      "{'Accuracy': 0.9024305555555555, 'Precision': 0.14953271028037382, 'Recall': 0.8571428571428571, 'F1': 0.2546419098143236}\n"
     ]
    }
   ],
   "source": [
    "X_train_oversampler, y_train_oversampler = random_oversampler(X_train_wordvec, y_train_wordvec)\n",
    "train_results, test_results = log_reg(X_train_oversampler,y_train_oversampler,X_test_wordvec,y_test_wordvec)\n",
    "print(train_results)\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune ADASYN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "nneighbors = []\n",
    "train_accuracy = []\n",
    "train_precision = []\n",
    "train_recall = []\n",
    "train_f1 = []\n",
    "\n",
    "test_accuracy = []\n",
    "test_precision = []\n",
    "test_recall = []\n",
    "test_f1 = []\n",
    "\n",
    "for i in list(range(n_neighbors[0], n_neighbors[1])):\n",
    "    print(i)\n",
    "    X_train_ADASYN, y_train_ADASYN = adasyn(X_train, y_train, n_neighbors = i)\n",
    "    train_results, test_results = log_reg(X_train_ADASYN,y_train_ADASYN,X_test,y_test)\n",
    "    nneighbors.append(i)\n",
    "    kneighbors.append(k)\n",
    "    samplingstrat.append(j)\n",
    "    train_accuracy.append(train_results['Accuracy'])\n",
    "    train_precision.append(train_results['Precision'])\n",
    "    train_recall.append(train_results['Recall'])\n",
    "    train_f1.append(train_results['F1'])\n",
    "\n",
    "    test_accuracy.append(test_results['Accuracy'])\n",
    "    test_precision.append(test_results['Precision'])\n",
    "    test_recall.append(test_results['Recall'])\n",
    "    test_f1.append(test_results['F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "adasyn_results = pd.DataFrame()\n",
    "adasyn_results['nneighbors'] = nneighbors\n",
    "adasyn_results['train_accuracy'] = train_accuracy\n",
    "adasyn_results['train_precision'] = train_precision\n",
    "adasyn_results['train_recall'] = train_recall\n",
    "adasyn_results['train_f1'] = train_f1\n",
    "adasyn_results['test_accuracy'] = test_accuracy\n",
    "adasyn_results['test_precision'] = test_precision\n",
    "adasyn_results['test_recall'] = test_recall\n",
    "adasyn_results['test_f1'] = test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nneighbors</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.908749</td>\n",
       "      <td>0.875813</td>\n",
       "      <td>0.952672</td>\n",
       "      <td>0.912627</td>\n",
       "      <td>0.855903</td>\n",
       "      <td>0.091116</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.161616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nneighbors  train_accuracy  train_precision  train_recall  train_f1  \\\n",
       "7           8        0.908749         0.875813      0.952672  0.912627   \n",
       "\n",
       "   test_accuracy  test_precision  test_recall   test_f1  \n",
       "7       0.855903        0.091116     0.714286  0.161616  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adasyn_results[adasyn_results['test_f1'] == adasyn_results['test_f1'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "nneighbors = []\n",
    "train_accuracy = []\n",
    "train_precision = []\n",
    "train_recall = []\n",
    "train_f1 = []\n",
    "\n",
    "test_accuracy = []\n",
    "test_precision = []\n",
    "test_recall = []\n",
    "test_f1 = []\n",
    "\n",
    "for i in list(range(n_neighbors[0], n_neighbors[1])):\n",
    "    print(i)\n",
    "    X_train_ADASYN, y_train_ADASYN = adasyn(X_train_wordvec, y_train_wordvec, n_neighbors = i)\n",
    "    train_results, test_results = log_reg(X_train_ADASYN,y_train_ADASYN,X_test_wordvec,y_test_wordvec)\n",
    "    nneighbors.append(i)\n",
    "    kneighbors.append(k)\n",
    "    samplingstrat.append(j)\n",
    "    train_accuracy.append(train_results['Accuracy'])\n",
    "    train_precision.append(train_results['Precision'])\n",
    "    train_recall.append(train_results['Recall'])\n",
    "    train_f1.append(train_results['F1'])\n",
    "\n",
    "    test_accuracy.append(test_results['Accuracy'])\n",
    "    test_precision.append(test_results['Precision'])\n",
    "    test_recall.append(test_results['Recall'])\n",
    "    test_f1.append(test_results['F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "adasyn_results_word2vec = pd.DataFrame()\n",
    "adasyn_results_word2vec['nneighbors'] = nneighbors\n",
    "adasyn_results_word2vec['train_accuracy'] = train_accuracy\n",
    "adasyn_results_word2vec['train_precision'] = train_precision\n",
    "adasyn_results_word2vec['train_recall'] = train_recall\n",
    "adasyn_results_word2vec['train_f1'] = train_f1\n",
    "adasyn_results_word2vec['test_accuracy'] = test_accuracy\n",
    "adasyn_results_word2vec['test_precision'] = test_precision\n",
    "adasyn_results_word2vec['test_recall'] = test_recall\n",
    "adasyn_results_word2vec['test_f1'] = test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nneighbors</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.950649</td>\n",
       "      <td>0.925427</td>\n",
       "      <td>0.98023</td>\n",
       "      <td>0.952041</td>\n",
       "      <td>0.909375</td>\n",
       "      <td>0.147766</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.247839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nneighbors  train_accuracy  train_precision  train_recall  train_f1  \\\n",
       "8           9        0.950649         0.925427       0.98023  0.952041   \n",
       "\n",
       "   test_accuracy  test_precision  test_recall   test_f1  \n",
       "8       0.909375        0.147766     0.767857  0.247839  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adasyn_results_word2vec[adasyn_results_word2vec['test_f1'] == adasyn_results_word2vec['test_f1'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def pca(n_components,X_train,X_test):\n",
    "    pca = PCA(n_components=n_components)\n",
    "\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test = pca.transform(X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "def kbest(k,X_train,X_test,y_train,y_test):\n",
    "    kbest = SelectKBest(k=k)\n",
    "    X_train = kbest.fit_transform(X_train, y_train)\n",
    "    X_test = kbest.transform(X_test)\n",
    "    return X_train, X_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N COMPONENTS: 5\n",
      "N COMPONENTS: 6\n",
      "N COMPONENTS: 7\n",
      "N COMPONENTS: 8\n",
      "N COMPONENTS: 9\n",
      "N COMPONENTS: 10\n",
      "N COMPONENTS: 11\n",
      "N COMPONENTS: 12\n",
      "N COMPONENTS: 13\n",
      "N COMPONENTS: 14\n",
      "N COMPONENTS: 15\n",
      "N COMPONENTS: 16\n",
      "N COMPONENTS: 17\n",
      "N COMPONENTS: 18\n",
      "N COMPONENTS: 19\n",
      "N COMPONENTS: 20\n",
      "N COMPONENTS: 21\n",
      "N COMPONENTS: 22\n",
      "N COMPONENTS: 23\n",
      "N COMPONENTS: 24\n",
      "N COMPONENTS: 25\n",
      "N COMPONENTS: 26\n",
      "N COMPONENTS: 27\n",
      "N COMPONENTS: 28\n",
      "N COMPONENTS: 29\n"
     ]
    }
   ],
   "source": [
    "## Best SMOTE \n",
    "results_pca = {}\n",
    "for i in range(5,30):\n",
    "    print(f'N COMPONENTS: {i}')\n",
    "    X_train_SMOTE, y_train_SMOTE = SMOTE_ENN(X_train, y_train, n_neighbours = 3, k_neighbours = 1, sampling_strategy = 0.1)\n",
    "    X_train_pca, X_test_pca = pca(i, X_train_SMOTE, X_test)\n",
    "    results_pca[i] = log_reg(X_train_pca,y_train_SMOTE, X_test_pca, y_test)[1]['F1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1782178217821782"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_n = max(results_pca, key=results_pca.get)\n",
    "results_pca[best_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N COMPONENTS: 5\n",
      "N COMPONENTS: 6\n",
      "N COMPONENTS: 7\n",
      "N COMPONENTS: 8\n",
      "N COMPONENTS: 9\n",
      "N COMPONENTS: 10\n",
      "N COMPONENTS: 11\n",
      "N COMPONENTS: 12\n",
      "N COMPONENTS: 13\n",
      "N COMPONENTS: 14\n",
      "N COMPONENTS: 15\n",
      "N COMPONENTS: 16\n",
      "N COMPONENTS: 17\n",
      "N COMPONENTS: 18\n",
      "N COMPONENTS: 19\n",
      "N COMPONENTS: 20\n",
      "N COMPONENTS: 21\n",
      "N COMPONENTS: 22\n",
      "N COMPONENTS: 23\n",
      "N COMPONENTS: 24\n",
      "N COMPONENTS: 25\n",
      "N COMPONENTS: 26\n",
      "N COMPONENTS: 27\n",
      "N COMPONENTS: 28\n",
      "N COMPONENTS: 29\n"
     ]
    }
   ],
   "source": [
    "results_kbest = {}\n",
    "for i in range(5,30):\n",
    "    print(f'N COMPONENTS: {i}')\n",
    "    X_train_SMOTE, y_train_SMOTE = SMOTE_ENN(X_train, y_train, n_neighbours = 3, k_neighbours = 1, sampling_strategy = 0.1)\n",
    "    X_train_kbest, X_test_kbest = kbest(i, X_train_SMOTE, X_test,y_train_SMOTE,y_test)\n",
    "    results_kbest[i] = log_reg(X_train_kbest,y_train_SMOTE, X_test_kbest, y_test)[1]['F1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24742268041237114"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_k = max(results_kbest, key=results_kbest.get)\n",
    "results_kbest[best_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N COMPONENTS: 5\n",
      "N COMPONENTS: 6\n",
      "N COMPONENTS: 7\n",
      "N COMPONENTS: 8\n",
      "N COMPONENTS: 9\n",
      "N COMPONENTS: 10\n",
      "N COMPONENTS: 11\n",
      "N COMPONENTS: 12\n",
      "N COMPONENTS: 13\n",
      "N COMPONENTS: 14\n",
      "N COMPONENTS: 15\n",
      "N COMPONENTS: 16\n",
      "N COMPONENTS: 17\n",
      "N COMPONENTS: 18\n",
      "N COMPONENTS: 19\n",
      "N COMPONENTS: 20\n",
      "N COMPONENTS: 21\n",
      "N COMPONENTS: 22\n",
      "N COMPONENTS: 23\n",
      "N COMPONENTS: 24\n",
      "N COMPONENTS: 25\n",
      "N COMPONENTS: 26\n",
      "N COMPONENTS: 27\n",
      "N COMPONENTS: 28\n",
      "N COMPONENTS: 29\n"
     ]
    }
   ],
   "source": [
    "results_pca = {}\n",
    "for i in range(5,30):\n",
    "    print(f'N COMPONENTS: {i}')\n",
    "    X_train_SMOTE, y_train_SMOTE = SMOTE_ENN(X_train_wordvec, y_train_wordvec, n_neighbours = 2, k_neighbours = 5, sampling_strategy = 0.1)\n",
    "    X_train_pca, X_test_pca = pca(i, X_train_SMOTE, X_test_wordvec)\n",
    "    results_pca[i] = log_reg(X_train_pca,y_train_SMOTE, X_test_pca, y_test_wordvec)[1]['F1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22857142857142854"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_n = max(results_pca, key=results_pca.get)\n",
    "results_pca[best_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N COMPONENTS: 5\n",
      "N COMPONENTS: 6\n",
      "N COMPONENTS: 7\n",
      "N COMPONENTS: 8\n",
      "N COMPONENTS: 9\n",
      "N COMPONENTS: 10\n",
      "N COMPONENTS: 11\n",
      "N COMPONENTS: 12\n",
      "N COMPONENTS: 13\n",
      "N COMPONENTS: 14\n",
      "N COMPONENTS: 15\n",
      "N COMPONENTS: 16\n",
      "N COMPONENTS: 17\n",
      "N COMPONENTS: 18\n",
      "N COMPONENTS: 19\n",
      "N COMPONENTS: 20\n",
      "N COMPONENTS: 21\n",
      "N COMPONENTS: 22\n",
      "N COMPONENTS: 23\n",
      "N COMPONENTS: 24\n",
      "N COMPONENTS: 25\n",
      "N COMPONENTS: 26\n",
      "N COMPONENTS: 27\n",
      "N COMPONENTS: 28\n",
      "N COMPONENTS: 29\n"
     ]
    }
   ],
   "source": [
    "results_kbest = {}\n",
    "for i in range(5,30):\n",
    "    print(f'N COMPONENTS: {i}')\n",
    "    X_train_SMOTE, y_train_SMOTE = SMOTE_ENN(X_train_wordvec, y_train_wordvec, n_neighbours = 3, k_neighbours = 1, sampling_strategy = 0.1)\n",
    "    X_train_kbest, X_test_kbest = kbest(i, X_train_SMOTE, X_test_wordvec,y_train_SMOTE,y_test_wordvec)\n",
    "    results_kbest[i] = log_reg(X_train_kbest,y_train_SMOTE, X_test_kbest, y_test_wordvec)[1]['F1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24175824175824176"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_k = max(results_kbest, key=results_kbest.get)\n",
    "results_kbest[best_k]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tensorflow_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63ebb5e79c6e3636f917fdf5f14d5096b2ad6379bef5dafefa30c414760b71f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
